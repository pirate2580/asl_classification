{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pirate2580/asl_classification/blob/main/YOLOTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFmF8-k4e-hd",
        "outputId": "9eea128f-6569-415f-947d-2d27a568a1dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['asl_alphabet_train',\n",
              " 'trainx.npy',\n",
              " 'trainy.npy',\n",
              " 'YOLO_predictions.ipynb',\n",
              " 'train_data',\n",
              " 'valx.npy',\n",
              " 'valy.npy',\n",
              " 'testx.npy',\n",
              " 'testy.npy',\n",
              " 'yolo_resnet_50.h5',\n",
              " 'YOLOASL.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"drive/My Drive/ASL_project\")\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBqh4bXf5C3S"
      },
      "outputs": [],
      "source": [
        "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "labels = {alphabet[i]: i for i in range(len(alphabet))}\n",
        "\n",
        "B = 1 # no. of bounding boxes\n",
        "N_CLASSES = 26                    # number of classes\n",
        "H, W = 224, 224\n",
        "SCREEN_HEIGHT = H\n",
        "SCREEN_WIDTH = W\n",
        "SPLIT_SIZE = H//32 # S=7\n",
        "N_EPOCHS = 135\n",
        "BATCH_SIZE = 32\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjcUj5la5D6d"
      },
      "outputs": [],
      "source": [
        "# List of file names\n",
        "in_file_names = [('train_data/' + str.lower(i) + '.npy') for i in alphabet]\n",
        "out_file_names = [('train_data/' + str.lower(i) + '_lab.npy') for i in alphabet]\n",
        "\n",
        "# Load data from each file into a list\n",
        "in_data_list = [np.load(file_name) for file_name in in_file_names]\n",
        "out_data_list = [np.load(file_name) for file_name in out_file_names]\n",
        "\n",
        "# Concatenate the list of arrays along the desired axis (e.g., axis=0 for stacking vertically)\n",
        "train_images = np.concatenate(in_data_list, axis=0)\n",
        "train_labels = np.concatenate(out_data_list, axis=0)\n",
        "\n",
        "# images to check the loss on over epochs\n",
        "val_images = np.load('valx.npy')\n",
        "val_labels = np.load('valy.npy')\n",
        "\n",
        "\n",
        "N_EXAMPLES = train_images.shape[0]\n",
        "\n",
        "\n",
        "#print(bboxes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_relative_bboxes(labels):\n",
        "  \"\"\"\n",
        "  Returns the original bounding boxes (matched by index) for each training label\n",
        "  along with the normalized training labels\n",
        "  \"\"\"\n",
        "  bounding_boxes = []\n",
        "  for i in range(labels.shape[0]):\n",
        "    xmin = labels[i][1]\n",
        "    ymin = labels[i][2]\n",
        "    xmax = labels[i][1] + labels[i][3]\n",
        "    ymax = labels[i][2] + labels[i][4]\n",
        "\n",
        "    bounding_box = [\n",
        "      (xmin+xmax)/(2 * SCREEN_WIDTH),\n",
        "      (ymin+ymax)/(2 * SCREEN_HEIGHT),\n",
        "      (xmax-xmin)/ SCREEN_WIDTH,\n",
        "      (ymax-ymin)/ SCREEN_HEIGHT\n",
        "    ]\n",
        "    bounding_boxes.append(bounding_box)\n",
        "\n",
        "\n",
        "  return np.stack(bounding_boxes, axis = 0)"
      ],
      "metadata": {
        "id": "IK08Z_ll0EZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_bboxes = find_relative_bboxes(train_labels)\n",
        "val_bboxes = find_relative_bboxes(val_labels)"
      ],
      "metadata": {
        "id": "5WiyInOX0HAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eezKGrMXncTN"
      },
      "outputs": [],
      "source": [
        "def generate_output(bounding_boxes, labels):\n",
        "\n",
        "  # N_EXAMPLESx7x7x31 tensor\n",
        "  output_label = np.zeros((bounding_boxes.shape[0],SPLIT_SIZE, SPLIT_SIZE, N_CLASSES + 5 * B))\n",
        "\n",
        "  for b in range(len(bounding_boxes)):\n",
        "\n",
        "    grid_x = bounding_boxes[b,0]*SPLIT_SIZE\n",
        "    grid_y = bounding_boxes[b,1]*SPLIT_SIZE\n",
        "\n",
        "    # i and j return the grid it belongs to\n",
        "    i = int(grid_x)\n",
        "    j = int(grid_y)\n",
        "    if (i >= SPLIT_SIZE):  i = SPLIT_SIZE - 1\n",
        "    if (i < 0): i = 0\n",
        "    if (j >= SPLIT_SIZE):  j = SPLIT_SIZE - 1\n",
        "    if (j < 0): j = 0\n",
        "    output_label[b, i, j, 0:5] = (1., grid_x % 1, grid_y % 1, bounding_boxes[b,2], bounding_boxes[b,3])\n",
        "\n",
        "    # assigns 1 to the appropriate label\n",
        "    output_label[b, i, j, 5:] = labels[b][5:]\n",
        "\n",
        "  return tf.convert_to_tensor(output_label, tf.float64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_output = generate_output(train_bboxes, train_labels)\n",
        "val_output = generate_output(val_bboxes, val_labels)"
      ],
      "metadata": {
        "id": "4quTJZx70Oee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFygC_yuFjUf"
      },
      "outputs": [],
      "source": [
        "# Create TensorFlow Datasets from NumPy array and TensorFlow tensor\n",
        "images_dataset = tf.data.Dataset.from_tensor_slices(train_images) # for all n images\n",
        "labels_dataset = tf.data.Dataset.from_tensor_slices(generate_output(train_bboxes, train_labels)) # generates label for 1 image\n",
        "\n",
        "val_images_dataset = tf.data.Dataset.from_tensor_slices(val_images) # for all n images\n",
        "val_labels_dataset = tf.data.Dataset.from_tensor_slices(generate_output(val_bboxes, val_labels)) # generates label for 1 image\n",
        "\n",
        "# Combine the two datasets into a single dataset\n",
        "train_dataset = tf.data.Dataset.zip((images_dataset, labels_dataset))\n",
        "val_dataset = tf.data.Dataset.zip((val_images_dataset, val_labels_dataset))\n",
        "\n",
        "train_dataset = (\n",
        "    train_dataset.\n",
        "    batch(BATCH_SIZE).\n",
        "    prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "val_dataset = (\n",
        "    val_dataset.\n",
        "    batch(BATCH_SIZE).\n",
        "    prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHpJcRbXGYPK"
      },
      "outputs": [],
      "source": [
        "NUM_FILTERS = 512\n",
        "OUTPUT_DIM = N_CLASSES + 5*B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RsCq15fGoUe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, MobileNet\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU, Flatten, Dense, Reshape, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Hy2uh8qGr3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488b30c3-5d36-4bce-9baf-293541df8893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17225924/17225924 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.applications.MobileNet(\n",
        "    weights = 'imagenet',\n",
        "    input_shape = (H, W, 3),\n",
        "    include_top = False\n",
        ")\n",
        "base_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiWAMTzpJoa1",
        "outputId": "d68b5220-79f5-4e68-cfba-f2c20657bb75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenet_1.00_224 (Functi  (None, 7, 7, 1024)        3228864   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 7, 7, 512)         4719104   \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 7, 7, 512)         2048      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 7, 7, 512)         2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 7, 7, 512)         2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               12845568  \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 512)               2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1519)              779247    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1519)              0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 31)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28660399 (109.33 MB)\n",
            "Trainable params: 28634415 (109.23 MB)\n",
            "Non-trainable params: 25984 (101.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    Conv2D(NUM_FILTERS, (3,3), padding = 'same', kernel_initializer = 'he_normal'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha = 0.1),\n",
        "\n",
        "    Conv2D(NUM_FILTERS, (3,3), padding = 'same', kernel_initializer = 'he_normal'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha = 0.1),\n",
        "\n",
        "    Conv2D(NUM_FILTERS, (3,3), padding = 'same', kernel_initializer = 'he_normal'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha = 0.1),\n",
        "\n",
        "    Conv2D(NUM_FILTERS, (3,3), padding = 'same', kernel_initializer = 'he_normal'),\n",
        "    LeakyReLU(alpha = 0.1),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "\n",
        "    Dense(NUM_FILTERS, kernel_initializer = 'he_normal'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha = 0.1),\n",
        "\n",
        "    Dropout(0.4),\n",
        "    Dense(SPLIT_SIZE * SPLIT_SIZE * OUTPUT_DIM, activation = 'sigmoid'),\n",
        "    Dropout(0.4),\n",
        "    Reshape((SPLIT_SIZE, SPLIT_SIZE, OUTPUT_DIM)),\n",
        "\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# YOLO-like model built on a MobileNet backbone pretrained on ImageNet dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXFod1VE2myq"
      },
      "outputs": [],
      "source": [
        "def difference(x, y):\n",
        "  return tf.reduce_sum(tf.square(y-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVo7jPYBS1Ax"
      },
      "outputs": [],
      "source": [
        "def compute_IOU(boxes1, boxes2):\n",
        "  \"\"\"\n",
        "  This function calculates the intersection over union of two bounding boxes\n",
        "  that are of type tensor\n",
        "  \"\"\"\n",
        "  boxes1_t = tf.stack([boxes1[...,0] - boxes1[..., 2] / 2.0,\n",
        "                       boxes1[...,1] - boxes1[..., 3] / 2.0,\n",
        "                       boxes1[...,0] + boxes1[..., 2] / 2.0,\n",
        "                       boxes1[...,1] + boxes1[..., 3] / 2.0],\n",
        "                      axis = -1)\n",
        "\n",
        "  boxes2_t = tf.stack([boxes2[...,0] - boxes2[...,2] / 2.0,\n",
        "                       boxes2[...,1] - boxes2[...,3] / 2.0,\n",
        "                       boxes2[...,0] + boxes2[...,2] / 2.0,\n",
        "                       boxes2[...,1] + boxes2[...,3] / 2.0],\n",
        "                      axis = -1)\n",
        "\n",
        "  lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n",
        "  rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n",
        "\n",
        "  intersection = tf.maximum(0.0, rd - lu)\n",
        "\n",
        "  inter_square = intersection[..., 0] * intersection[..., 1]\n",
        "\n",
        "  square1 = boxes1[..., 2] * boxes1[..., 3]\n",
        "  square2 = boxes2[..., 2] * boxes2[..., 3]\n",
        "\n",
        "  union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
        "  return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUif4jimMBr2"
      },
      "outputs": [],
      "source": [
        "def yolo_loss(y_true, y_pred):\n",
        "  '''\n",
        "  y_true = 7x7x31 where 31 is from [p, bx, by, bw, bh, 26 classes...]\n",
        "  y_pred = 7x7x31 where 31 is from [p, bx, by, bw, bh, 26 classes...]\n",
        "  '''\n",
        "  # Note: parameters have been changed from the original paper from 0.5, 5 to\n",
        "  # the values below\n",
        "  # this is because the model tends to make errors in class predictions too often\n",
        "  # lowering the parameter values for no object and coordinate allows more focus on\n",
        "  # class error\n",
        "  lambda_no_obj = 0.01\n",
        "  lambda_coord = 0.5\n",
        "\n",
        "  '--------------------------------------------------------------------------------------------------------------------------------------------------------'\n",
        "  #Object Loss\n",
        "  target = y_true[..., 0]\n",
        "\n",
        "\n",
        "  y_pred_extract = tf.gather_nd(y_pred, tf.where(target[:] == 1))\n",
        "  y_target_extract = tf.gather_nd(y_true, tf.where(target[:] == 1))\n",
        "\n",
        "  rescaler = tf.where(target[:] == 1) * 32\n",
        "\n",
        "  upscaler_1 = tf.concat([rescaler[:,1:], tf.zeros([len(rescaler),2], dtype = tf.int64)], axis =-1)\n",
        "\n",
        "  target_upscaler_2 = tf.repeat([[32., 32., 224., 224.]], repeats = [len(rescaler)], axis = 0) * tf.cast(y_target_extract[...,1:5], dtype = tf.float32)\n",
        "\n",
        "  pred_1_upscaler_2 = tf.repeat([[32., 32., 224., 224.]], repeats = [len(rescaler)], axis = 0) * tf.cast(y_target_extract[...,1:5], dtype = tf.float32)\n",
        "\n",
        "  target_orig = tf.cast(upscaler_1, dtype = tf.float32) + target_upscaler_2\n",
        "  pred_1_orig = tf.cast(upscaler_1, dtype = tf.float32) + pred_1_upscaler_2\n",
        "\n",
        "\n",
        "  mask = tf.cast(compute_IOU(target_orig, pred_1_orig), dtype = tf.int32)\n",
        "\n",
        "  y_pred_joined = tf.transpose(tf.concat([tf.expand_dims(y_pred_extract[...,0], axis=0)], axis=0))\n",
        "\n",
        "  obj_pred = tf.gather_nd(y_pred_joined, tf.stack([tf.range(len(rescaler)), mask], axis = -1))\n",
        "\n",
        "  object_loss = difference(tf.cast(obj_pred, dtype = tf.float32), tf.cast(tf.ones([len(rescaler)]), dtype = tf.float32))\n",
        "  '--------------------------------------------------------------------------------------------------------------------------------------------------------'\n",
        "  # No object loss\n",
        "  y_pred_extract = tf.gather_nd(y_pred[...,0: 5], tf.where(target[:] == 0))\n",
        "  y_target_extract = tf.zeros(len(y_pred_extract))\n",
        "\n",
        "  no_object_loss_1 = difference(tf.cast(y_pred_extract[...,0], dtype = tf.float32), tf.cast(y_target_extract, dtype = tf.float32))\n",
        "\n",
        "  no_object_loss = no_object_loss_1\n",
        "  '--------------------------------------------------------------------------------------------------------------------------------------------------------'\n",
        "  # Object Class Loss\n",
        "  y_pred_extract = tf.gather_nd(y_pred[..., B * 5: ], tf.where(target[:] == 1))\n",
        "  class_extract = tf.gather_nd(y_true[..., 5:], tf.where(target[:] == 1))\n",
        "\n",
        "  class_loss = difference(tf.cast(y_pred_extract, dtype = tf.float32), tf.cast(class_extract, dtype = tf.float32))\n",
        "  '--------------------------------------------------------------------------------------------------------------------------------------------------------'\n",
        "  # For object bounding box loss\n",
        "  y_pred_extract = tf.gather_nd(y_pred[...,0: B * 5], tf.where(target[:] == 1))\n",
        "  centre_joined = tf.stack([y_pred_extract[...,1:3]], axis = 1)\n",
        "\n",
        "  centre_pred = tf.gather_nd(centre_joined, tf.stack([tf.range(len(rescaler)), mask], axis =-1))\n",
        "  centre_target = tf.gather_nd(y_true[...,1:3], tf.where(target[:] == 1))\n",
        "\n",
        "  centre_loss = difference(centre_pred, centre_target)\n",
        "\n",
        "  size_joined = tf.stack([y_pred_extract[...,3:5]],axis = 1)\n",
        "\n",
        "  size_pred = tf.gather_nd(size_joined, tf.stack([tf.range(len(rescaler)), mask], axis =-1))\n",
        "  size_target = tf.gather_nd(y_true[...,3:5], tf.where(target[:] == 1))\n",
        "\n",
        "  size_loss = difference(tf.math.sqrt(tf.math.abs(size_pred)), tf.math.sqrt(tf.math.abs(size_target)))\n",
        "\n",
        "  box_loss = centre_loss + size_loss\n",
        "  '--------------------------------------------------------------------------------------------------------------------------------------------------------'\n",
        "\n",
        "  loss = object_loss + (lambda_no_obj * no_object_loss) + tf.cast(lambda_coord * box_loss, dtype = tf.float32) + tf.cast(class_loss, dtype = tf.float32)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gt5ZkZX3hPso"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = '/content/drive/MyDrive/ASL_project/yolo_mobilenet.h5'\n",
        "\n",
        "\n",
        "callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_filepath,\n",
        "    save_weights_only = True,\n",
        "    monitor = 'val_loss',\n",
        "    mode = 'min',\n",
        "    save_best_only = True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG-0nfrmiIXg"
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 10:\n",
        "    return 5e-5\n",
        "  elif 10<=epoch<20:\n",
        "    return 1e-5\n",
        "  else:\n",
        "    return 1e-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKKDOWKB-f09"
      },
      "outputs": [],
      "source": [
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUl8DEgKiT2R"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "model.compile(\n",
        "    loss = yolo_loss,\n",
        "    optimizer = optimizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y45DMh7S-2E7",
        "outputId": "efe22ad5-94f3-4a0e-bd45-5f97bcbf25ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy0H_pHc_BNI",
        "outputId": "18a17e7a-7eaf-4073-a17a-27b5fcff9b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "409/409 [==============================] - 68s 134ms/step - loss: 67.1152 - val_loss: 76.1880 - lr: 5.0000e-05\n",
            "Epoch 2/30\n",
            "409/409 [==============================] - 58s 143ms/step - loss: 67.3682 - val_loss: 75.2173 - lr: 5.0000e-05\n",
            "Epoch 3/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 67.0522 - val_loss: 75.4597 - lr: 5.0000e-05\n",
            "Epoch 4/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 67.4379 - val_loss: 75.7232 - lr: 5.0000e-05\n",
            "Epoch 5/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 66.9343 - val_loss: 75.3045 - lr: 5.0000e-05\n",
            "Epoch 6/30\n",
            "409/409 [==============================] - 57s 138ms/step - loss: 66.8553 - val_loss: 76.0867 - lr: 5.0000e-05\n",
            "Epoch 7/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 67.0548 - val_loss: 75.4000 - lr: 5.0000e-05\n",
            "Epoch 8/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 67.0233 - val_loss: 75.7852 - lr: 5.0000e-05\n",
            "Epoch 9/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 66.4596 - val_loss: 75.3703 - lr: 5.0000e-05\n",
            "Epoch 10/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 66.6819 - val_loss: 75.8710 - lr: 5.0000e-05\n",
            "Epoch 11/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 66.7548 - val_loss: 75.2449 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "409/409 [==============================] - 58s 141ms/step - loss: 66.2721 - val_loss: 75.1371 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "409/409 [==============================] - 58s 143ms/step - loss: 66.2178 - val_loss: 75.0224 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 65.8915 - val_loss: 75.3175 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 65.8931 - val_loss: 75.0844 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "409/409 [==============================] - 56s 137ms/step - loss: 65.8848 - val_loss: 75.0472 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 65.6837 - val_loss: 75.2063 - lr: 1.0000e-05\n",
            "Epoch 18/30\n",
            "409/409 [==============================] - 58s 142ms/step - loss: 65.7903 - val_loss: 75.0120 - lr: 1.0000e-05\n",
            "Epoch 19/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 65.4758 - val_loss: 75.1137 - lr: 1.0000e-05\n",
            "Epoch 20/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 65.7330 - val_loss: 75.0753 - lr: 1.0000e-05\n",
            "Epoch 21/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 65.7241 - val_loss: 75.0687 - lr: 1.0000e-06\n",
            "Epoch 22/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 65.8749 - val_loss: 75.0769 - lr: 1.0000e-06\n",
            "Epoch 23/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 65.9310 - val_loss: 75.1038 - lr: 1.0000e-06\n",
            "Epoch 24/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 65.8264 - val_loss: 75.1096 - lr: 1.0000e-06\n",
            "Epoch 25/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 65.7669 - val_loss: 75.1181 - lr: 1.0000e-06\n",
            "Epoch 26/30\n",
            "409/409 [==============================] - 57s 139ms/step - loss: 65.7023 - val_loss: 75.1397 - lr: 1.0000e-06\n",
            "Epoch 27/30\n",
            "409/409 [==============================] - 56s 137ms/step - loss: 65.5161 - val_loss: 75.1314 - lr: 1.0000e-06\n",
            "Epoch 28/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 65.5293 - val_loss: 75.1273 - lr: 1.0000e-06\n",
            "Epoch 29/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 65.4670 - val_loss: 75.1338 - lr: 1.0000e-06\n",
            "Epoch 30/30\n",
            "409/409 [==============================] - 56s 138ms/step - loss: 65.5560 - val_loss: 75.1104 - lr: 1.0000e-06\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data = val_dataset,\n",
        "    verbose = 1,\n",
        "    epochs = 30,\n",
        "    callbacks = [lr_callback, callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FERQl8Y7tN2",
        "outputId": "42cbf5f1-5641-48c9-f5d8-db68e508abd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 224, 224, 3)\n",
            "(100, 31)\n",
            "(100, 4)\n",
            "(100, 7, 7, 31)\n"
          ]
        }
      ],
      "source": [
        "test_images = np.load('testx.npy')\n",
        "test_labels = np.load('testy.npy')\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)\n",
        "test_bboxes = find_relative_bboxes(test_labels)\n",
        "print(test_bboxes.shape)\n",
        "test_output = generate_output(test_bboxes, test_labels)\n",
        "print(test_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdTCybF479sb"
      },
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.MobileNet(\n",
        "    weights = 'imagenet',\n",
        "    input_shape = (H, W, 3),\n",
        "    include_top = False\n",
        ")\n",
        "base_model.trainable = True\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    Conv2D(NUM_FILTERS, (3,3), padding = 'same', kernel_initializer = 'he_normal'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha = 0.1),\n",
        "\n",
        "    Conv2D(NUM_FILTERS, (3,3), padding = 'same', kernel_initializer = 'he_normal'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha = 0.1),\n",
        "\n",
        "    Conv2D(NUM_FILTERS, (3,3), padding = 'same', kernel_initializer = 'he_normal'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha = 0.1),\n",
        "\n",
        "    Conv2D(NUM_FILTERS, (3,3), padding = 'same', kernel_initializer = 'he_normal'),\n",
        "    LeakyReLU(alpha = 0.1),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "\n",
        "    Dense(NUM_FILTERS, kernel_initializer = 'he_normal'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha = 0.1),\n",
        "\n",
        "    Dropout(0.5),\n",
        "    Dense(SPLIT_SIZE * SPLIT_SIZE * OUTPUT_DIM, activation = 'sigmoid'),\n",
        "    Dropout(0.5),\n",
        "    Reshape((SPLIT_SIZE, SPLIT_SIZE, OUTPUT_DIM)),\n",
        "\n",
        "])\n",
        "\n",
        "model.load_weights('/content/drive/MyDrive/ASL_project/yolo_mobilenet.h5')\n",
        "\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "model.compile(\n",
        "    loss = yolo_loss,\n",
        "    optimizer = optimizer,\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1eVy-NL7V4Ad1OvSsJNhbvv83ETnBOzZW",
      "authorship_tag": "ABX9TyNk4V9vXBw/uxv89PS6PtrB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}